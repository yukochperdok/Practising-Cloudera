0. Investigamos la BBDD de Mysql:
[cloudera@quickstart ~]$ mysql -u root -pcloudera
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 194
Server version: 5.1.73 Source distribution

Copyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases
    -> ;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| cm                 |
| firehose           |
| hue                |
| metastore          |
| movielens          |
| mysql              |
| nav                |
| navms              |
| oozie              |
| retail_db          |
| rman               |
| sentry             |
+--------------------+
13 rows in set (0.00 sec)

mysql> use retail_db;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql> select * from departments;
+---------------+-----------------+
| department_id | department_name |
+---------------+-----------------+
|             2 | Fitness         |
|             3 | Footwear        |
|             4 | Apparel         |
|             5 | Golf            |
|             6 | Outdoors        |
|             7 | Fan Shop        |
+---------------+-----------------+
6 rows in set (0.00 sec)



1. sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table departments --target-dir /user/cloudera/departments

[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/departments
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2016-07-28 02:43 /user/cloudera/departments/_SUCCESS
-rw-r--r--   1 cloudera cloudera         21 2016-07-28 02:43 /user/cloudera/departments/part-m-00000
-rw-r--r--   1 cloudera cloudera         10 2016-07-28 02:43 /user/cloudera/departments/part-m-00001
-rw-r--r--   1 cloudera cloudera          7 2016-07-28 02:43 /user/cloudera/departments/part-m-00002
-rw-r--r--   1 cloudera cloudera         22 2016-07-28 02:43 /user/cloudera/departments/part-m-00003
[cloudera@quickstart ~]$ hadoop fs -text /user/cloudera/departments/part-m-00000
2,Fitness
3,Footwear



2. sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table departments --target-dir /user/cloudera/departments --num-mappers 1

[cloudera@quickstart ~]$ hadoop fs -text /user/cloudera/departments/part-m-00000
2,Fitness
3,Footwear
4,Apparel
5,Golf
6,Outdoors
7,Fan Shop


3. sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table departments --target-dir /user/cloudera/departments --num-mappers 1 --where department_id=3

[cloudera@quickstart ~]$ hadoop fs -text /user/cloudera/departments/part-m-00000
3,Footwear


4. sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table departments --target-dir /user/cloudera/departments --num-mappers 1 --compress

[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/departments
Found 2 items
-rw-r--r--   1 cloudera cloudera          0 2016-07-28 02:48 /user/cloudera/departments/_SUCCESS
-rw-r--r--   1 cloudera cloudera         80 2016-07-28 02:48 /user/cloudera/departments/part-m-00000.gz


AHORA con codec de compresion:

[cloudera@quickstart ~]$ sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table departments --target-dir /user/cloudera/departments --num-mappers 1 --compress --compression-codec org.apache.hadoop.io.compress.SnappyCodec
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/08 10:53:17 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/08 10:53:17 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/08 10:53:18 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/08 10:53:18 INFO tool.CodeGenTool: Beginning code generation
16/09/08 10:53:19 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `departments` AS t LIMIT 1
16/09/08 10:53:19 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `departments` AS t LIMIT 1
16/09/08 10:53:19 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/e3da8d0ab2a36b5b47fdbb2fad03a3ff/departments.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/09/08 10:53:24 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/e3da8d0ab2a36b5b47fdbb2fad03a3ff/departments.jar
16/09/08 10:53:24 WARN manager.MySQLManager: It looks like you are importing from mysql.
16/09/08 10:53:24 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
16/09/08 10:53:24 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
16/09/08 10:53:24 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
16/09/08 10:53:24 INFO mapreduce.ImportJobBase: Beginning import of departments
16/09/08 10:53:24 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/08 10:53:25 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/09/08 10:53:26 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/09/08 10:53:27 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/08 10:53:30 INFO db.DBInputFormat: Using read commited transaction isolation
16/09/08 10:53:30 INFO mapreduce.JobSubmitter: number of splits:1
16/09/08 10:53:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1473156829873_0016
16/09/08 10:53:32 INFO impl.YarnClientImpl: Submitted application application_1473156829873_0016
16/09/08 10:53:32 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1473156829873_0016/
16/09/08 10:53:32 INFO mapreduce.Job: Running job: job_1473156829873_0016
16/09/08 10:53:47 INFO mapreduce.Job: Job job_1473156829873_0016 running in uber mode : false
16/09/08 10:53:47 INFO mapreduce.Job:  map 0% reduce 0%
16/09/08 10:53:58 INFO mapreduce.Job:  map 100% reduce 0%
16/09/08 10:53:58 INFO mapreduce.Job: Job job_1473156829873_0016 completed successfully
16/09/08 10:53:59 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=138935
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=87
		HDFS: Number of bytes written=70
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Other local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8982
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=8982
		Total vcore-seconds taken by all map tasks=8982
		Total megabyte-seconds taken by all map tasks=9197568
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Input split bytes=87
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=102
		CPU time spent (ms)=2370
		Physical memory (bytes) snapshot=198082560
		Virtual memory (bytes) snapshot=1569710080
		Total committed heap usage (bytes)=196608000
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=70
16/09/08 10:53:59 INFO mapreduce.ImportJobBase: Transferred 70 bytes in 32.2489 seconds (2.1706 bytes/sec)
16/09/08 10:53:59 INFO mapreduce.ImportJobBase: Retrieved 6 records.


[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/departments
Found 2 items
-rw-r--r--   1 cloudera cloudera          0 2016-09-08 10:53 /user/cloudera/departments/_SUCCESS
-rw-r--r--   1 cloudera cloudera         70 2016-09-08 10:53 /user/cloudera/departments/part-m-00000.snappy
[cloudera@quickstart ~]$ hadoop fs -cat /user/cloudera/departments/part-m-00000.snappy
<><�2,Fitness
3,Footwear
4,Apparel
5,Golf
6,Outdoors
7,Fan Shop



5. sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table departments --target-dir /user/cloudera/departments --num-mappers 1 --as-avrodatafile

[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/departments
Found 2 items
-rw-r--r--   1 cloudera cloudera          0 2016-07-28 02:51 /user/cloudera/departments/_SUCCESS
-rw-r--r--   1 cloudera cloudera        450 2016-07-28 02:51 /user/cloudera/departments/part-m-00000.avro
[cloudera@quickstart ~]$ hadoop fs -cat /user/cloudera/departments/part-m-00000.avro
Objavro.schema�{"type":"record","name":"departments","doc":"Sqoop import of departments","fields":[{"name":"department_id","type":["null","int"],"default":null,"columnName":"department_id","sqlType":"4"},{"name":"department_name","type":["null","string"],"default":null,"columnName":"department_name","sqlType":"12"}],"tableName":"departments"}{M ��d���Z��
                            �FitnessFootwearApparel
Golf
     OutdoorsFan Shop{M ��d���Z��[cloudera@quickstart ~]$


6. sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table departments --target-dir /user/cloudera/departments --num-mappers 1 --direct

[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/departments
Found 2 items
-rw-r--r--   1 cloudera cloudera          0 2016-07-28 02:58 /user/cloudera/departments/_SUCCESS
-rw-r--r--   1 cloudera cloudera         60 2016-07-28 02:58 /user/cloudera/departments/part-m-00000
[cloudera@quickstart ~]$ hadoop fs -cat /user/cloudera/departments/part-m-00000
2,Fitness
3,Footwear
4,Apparel
5,Golf
6,Outdoors
7,Fan Shop





OTRAS OPERACIONES:
7. Ayuda
[cloudera@quickstart init.d]$ sqoop help
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/07 04:57:57 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
usage: sqoop COMMAND [ARGS]

Available commands:
  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  eval               Evaluate a SQL statement and display the results
  export             Export an HDFS directory to a database table
  help               List available commands
  import             Import a table from a database to HDFS
  import-all-tables  Import tables from a database to HDFS
  import-mainframe   Import datasets from a mainframe server to HDFS
  job                Work with saved jobs
  list-databases     List available databases on a server
  list-tables        List available tables in a database
  merge              Merge results of incremental imports
  metastore          Run a standalone Sqoop metastore
  version            Display version information

See 'sqoop help COMMAND' for information on a specific command.



[cloudera@quickstart init.d]$ sqoop help eval
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/07 04:58:34 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
usage: sqoop eval [GENERIC-ARGS] [TOOL-ARGS]

Common arguments:
   --connect <jdbc-uri>                         Specify JDBC connect
                                                string
   --connection-manager <class-name>            Specify connection manager
                                                class name
   --connection-param-file <properties-file>    Specify connection
                                                parameters file
   --driver <class-name>                        Manually specify JDBC
                                                driver class to use
   --hadoop-home <hdir>                         Override
                                                $HADOOP_MAPRED_HOME_ARG
   --hadoop-mapred-home <dir>                   Override
                                                $HADOOP_MAPRED_HOME_ARG
   --help                                       Print usage instructions
-P                                              Read password from console
   --password <password>                        Set authentication
                                                password
   --password-alias <password-alias>            Credential provider
                                                password alias
   --password-file <password-file>              Set authentication
                                                password file path
   --relaxed-isolation                          Use read-uncommitted
                                                isolation for imports
   --skip-dist-cache                            Skip copying jars to
                                                distributed cache
   --username <username>                        Set authentication
                                                username
   --verbose                                    Print more information
                                                while working

SQL evaluation arguments:
-e,--query <statement>    Execute 'statement' in SQL and exit

Generic Hadoop command-line arguments:
(must preceed any tool-specific arguments)
Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|resourcemanager:port>    specify a ResourceManager
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]





8. Listar tablas y databases

[cloudera@quickstart init.d]$ sqoop list-databases --connect jdbc:mysql://localhost --username root --password cloudera
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/07 05:08:20 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/07 05:08:20 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/07 05:08:20 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
information_schema
cm
firehose
hue
metastore
movielens
mysql
nav
navms
oozie
retail_db
rman
sentry



[cloudera@quickstart init.d]$ sqoop list-tables --connect jdbc:mysql://localhost/retail_db --username root --password cloudera
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/07 05:03:31 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/07 05:03:31 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/07 05:03:32 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
categories
customers
departments
order_items
orders
products

9. Evaluar consulta

[cloudera@quickstart init.d]$ sqoop eval --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --query 'SELECT * FROM departments'
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/07 05:01:18 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/07 05:01:18 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/07 05:01:18 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
--------------------------------------
| department_id | department_name      | 
--------------------------------------
| 2           | Fitness              | 
| 3           | Footwear             | 
| 4           | Apparel              | 
| 5           | Golf                 | 
| 6           | Outdoors             | 
| 7           | Fan Shop             | 
--------------------------------------

10. Cargar una definicion de tabla directamente en HIVE:
Importante cuando la cargo desde sqoop, me crea la definicion de la tabla pero no los datos. Los tengo que cargar a mano:

[cloudera@quickstart Desktop]$ sqoop create-hive-table --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table products --hive-table productos --fields-terminated-by ';' --hive-overwrite
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/07 05:54:45 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/07 05:54:45 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/07 05:54:46 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/07 05:54:46 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `products` AS t LIMIT 1
16/09/07 05:54:46 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `products` AS t LIMIT 1
16/09/07 05:54:47 INFO hive.HiveImport: Loading uploaded data into Hive

Logging initialized using configuration in jar:file:/usr/jars/hive-common-1.1.0-cdh5.7.0.jar!/hive-log4j.properties
OK
Time taken: 1.136 seconds


hive> show tables;
OK
customers
dep
departamentos
order_details
orders
productos
products
Time taken: 0.068 seconds, Fetched: 7 row(s)


Se carga el siguiente archivo editado:
1273641;Chestnut;USB Card Reader;1839;1275;1
1273642;Ultramegaco;USB Card Reader;1949;721;1
1273643;McDowell;USB Card Reader;2149;845;1


hive> load data inpath '/user/cloudera/part-m-00000' into table productos
    > ;
Loading data to table default.productos
chgrp: changing ownership of 'hdfs://quickstart.cloudera:8020/user/hive/warehouse/productos/part-m-00000': User does not belong to supergroup
Table default.productos stats: [numFiles=1, totalSize=137]
OK
Time taken: 0.733 seconds
hive> select * from productos;
OK
1273641	NULL	USB Card Reader	1839	1275.0	1
1273642	NULL	USB Card Reader	1949	721.0	1
1273643	NULL	USB Card Reader	2149	845.0	1
Time taken: 0.341 seconds, Fetched: 4 row(s)

PORQUE APARECE NULL??

hive> describe productos;
OK
product_id          	int                 	                    
product_category_id 	int                 	                    
product_name        	string              	                    
product_description 	string              	                    
product_price       	double              	                    
product_image       	string              	                    
Time taken: 0.082 seconds, Fetched: 6 row(s)

IMP: Es en el import donde crea la carpeta, un en el load dat donde recoge los ficheros y los carga. Con el create-hive-table solo genera la definicion.

11. Importar a Hive directamente.


[cloudera@quickstart Desktop]$ sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table products --warehouse-dir /tmp --fields-terminated-by '|' --lines-terminated-by '\n' --hive-import --hive-table productos --hive-home /user/cloudera/productos
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/07 09:37:17 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/07 09:37:17 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/07 09:37:17 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/07 09:37:17 INFO tool.CodeGenTool: Beginning code generation
16/09/07 09:37:18 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `products` AS t LIMIT 1
16/09/07 09:37:18 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `products` AS t LIMIT 1
16/09/07 09:37:18 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/54fd20b463494144eb164e64c3ce2952/products.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/09/07 09:37:19 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/54fd20b463494144eb164e64c3ce2952/products.jar
16/09/07 09:37:19 WARN manager.MySQLManager: It looks like you are importing from mysql.
16/09/07 09:37:19 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
16/09/07 09:37:19 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
16/09/07 09:37:19 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
16/09/07 09:37:19 INFO mapreduce.ImportJobBase: Beginning import of products
16/09/07 09:37:19 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/07 09:37:20 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/09/07 09:37:20 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/09/07 09:37:20 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/07 09:37:22 INFO db.DBInputFormat: Using read commited transaction isolation
16/09/07 09:37:22 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`product_id`), MAX(`product_id`) FROM `products`
16/09/07 09:37:22 INFO db.IntegerSplitter: Split size: 336; Num splits: 4 from: 1 to: 1345
16/09/07 09:37:22 INFO mapreduce.JobSubmitter: number of splits:4
16/09/07 09:37:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1473156829873_0013
16/09/07 09:37:23 INFO impl.YarnClientImpl: Submitted application application_1473156829873_0013
16/09/07 09:37:23 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1473156829873_0013/
16/09/07 09:37:23 INFO mapreduce.Job: Running job: job_1473156829873_0013
16/09/07 09:37:30 INFO mapreduce.Job: Job job_1473156829873_0013 running in uber mode : false
16/09/07 09:37:30 INFO mapreduce.Job:  map 0% reduce 0%
16/09/07 09:37:38 INFO mapreduce.Job:  map 25% reduce 0%
16/09/07 09:37:40 INFO mapreduce.Job:  map 50% reduce 0%
16/09/07 09:37:41 INFO mapreduce.Job:  map 75% reduce 0%
16/09/07 09:37:42 INFO mapreduce.Job:  map 100% reduce 0%
16/09/07 09:37:42 INFO mapreduce.Job: Job job_1473156829873_0013 completed successfully
16/09/07 09:37:42 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=555732
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=474
		HDFS: Number of bytes written=173993
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Job Counters 
		Launched map tasks=4
		Other local map tasks=4
		Total time spent by all maps in occupied slots (ms)=26485
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=26485
		Total vcore-seconds taken by all map tasks=26485
		Total megabyte-seconds taken by all map tasks=27120640
	Map-Reduce Framework
		Map input records=1345
		Map output records=1345
		Input split bytes=474
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=309
		CPU time spent (ms)=4010
		Physical memory (bytes) snapshot=707391488
		Virtual memory (bytes) snapshot=6270488576
		Total committed heap usage (bytes)=792199168
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=173993
16/09/07 09:37:42 INFO mapreduce.ImportJobBase: Transferred 169.915 KB in 22.0095 seconds (7.7201 KB/sec)
16/09/07 09:37:42 INFO mapreduce.ImportJobBase: Retrieved 1345 records.
16/09/07 09:37:42 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `products` AS t LIMIT 1
16/09/07 09:37:42 INFO hive.HiveImport: Loading uploaded data into Hive

Logging initialized using configuration in jar:file:/usr/jars/hive-common-1.1.0-cdh5.7.0.jar!/hive-log4j.properties
OK
Time taken: 1.202 seconds
Loading data to table default.productos
Table default.productos stats: [numFiles=4, totalSize=173993]
OK
Time taken: 0.651 seconds
[cloudera@quickstart Desktop]$ hive
2016-09-07 09:38:45,231 WARN  [main] mapreduce.TableMapReduceUtil: The hbase-prefix-tree module jar containing PrefixTreeCodec is not present.  Continuing without it.

Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
WARNING: Hive CLI is deprecated and migration to Beeline is recommended.
hive> show tables;
OK
customers
departamentos
order_details
orders
productos
Time taken: 0.643 seconds, Fetched: 5 row(s)
hive> select * from productos limit 9;
OK
1	2	Quest Q64 10 FT. x 10 FT. Slant Leg Instant U		59.98	http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy
2	2	Under Armour Men's Highlight MC Football Clea		129.99	http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat
3	2	Under Armour Men's Renegade D Mid Football Cl		89.99	http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat
4	2	Under Armour Men's Renegade D Mid Football Cl		89.99	http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat
5	2	Riddell Youth Revolution Speed Custom Footbal		199.99	http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet
6	2	Jordan Men's VI Retro TD Football Cleat		134.99	http://images.acmesports.sports/Jordan+Men%27s+VI+Retro+TD+Football+Cleat
7	2	Schutt Youth Recruit Hybrid Custom Football H		99.99	http://images.acmesports.sports/Schutt+Youth+Recruit+Hybrid+Custom+Football+Helmet+2014
8	2	Nike Men's Vapor Carbon Elite TD Football Cle		129.99	http://images.acmesports.sports/Nike+Men%27s+Vapor+Carbon+Elite+TD+Football+Cleat
9	2	Nike Adult Vapor Jet 3.0 Receiver Gloves		50.0	http://images.acmesports.sports/Nike+Adult+Vapor+Jet+3.0+Receiver+Gloves

[cloudera@quickstart Desktop]$ hadoop fs -ls /user/hive/warehouse/productos
Found 4 items
-rwxrwxrwx   1 cloudera supergroup      41419 2016-09-07 09:37 /user/hive/warehouse/productos/part-m-00000
-rwxrwxrwx   1 cloudera supergroup      43660 2016-09-07 09:37 /user/hive/warehouse/productos/part-m-00001
-rwxrwxrwx   1 cloudera supergroup      42195 2016-09-07 09:37 /user/hive/warehouse/productos/part-m-00002
-rwxrwxrwx   1 cloudera supergroup      46719 2016-09-07 09:37 /user/hive/warehouse/productos/part-m-00003
[cloudera@quickstart Desktop]$ hadoop fs -cat /user/hive/warehouse/productos/part-m-00000
1|2|Quest Q64 10 FT. x 10 FT. Slant Leg Instant U||59.98|http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy
2|2|Under Armour Men's Highlight MC Football Clea||129.99|http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat
3|2|Under Armour Men's Renegade D Mid Football Cl||89.99|http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat
4|2|Under Armour Men's Renegade D Mid Football Cl||89.99|http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat
5|2|Riddell Youth Revolution Speed Custom Footbal||199.99|http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet
6|2|Jordan Men's VI Retro TD Football Cleat||134.99|http://images.acmesports.sports/Jordan+Men%27s+VI+Retro+TD+Football+Cleat
7|2|Schutt Youth Recruit Hybrid Custom Football H||99.99|http://images.acmesports.sports/Schutt+Youth+Recruit+Hybrid+Custom+Football+Helmet+2014
8|2|Nike Men's Vapor Carbon Elite TD Football Cle||129.99|http://images.acmesports.sports/Nike+Men%27s+Vapor+Carbon+Elite+TD+Football+Cleat
9|2|Nike Adult Vapor Jet 3.0 Receiver Gloves||50.0|http://images.acmesports.sports/Nike+Adult+Vapor+Jet+3.0+Receiver+Gloves
10|2|Under Armour Men's Highlight MC Football Clea||129.99|http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat
11|2|Fitness Gear 300 lb Olympic Weight Set||209.99|http://images.acmesports.sports/Fitness+Gear+300+lb+Olympic+Weight+Set
12|2|Under Armour Men's Highlight MC Alter Ego Fla||139.99|http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Alter+Ego+Flash+Football...
13|2|Under Armour Men's Renegade D Mid Football Cl||89.99|http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat

Aqui si se cargan directamente en HIVE.



12. Importar tabla con fichero de configuracion
sqoop --options-file ./config/SqoopImportOptions.txt --table departments --target-dir /user/cloudera/departments --num-mappers 1

[cloudera@quickstart Ejercicios Iniciales]$ sqoop --options-file ./config/SqoopImportOptions.txt --table departments --target-dir /user/cloudera/departments --num-mappers 1
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 02:46:23 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/09 02:46:23 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/09 02:46:23 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/09 02:46:23 INFO tool.CodeGenTool: Beginning code generation
16/09/09 02:46:23 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `departments` AS t LIMIT 1
16/09/09 02:46:23 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `departments` AS t LIMIT 1
16/09/09 02:46:23 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/63edd55f971e2529552a65f1fba19135/departments.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/09/09 02:46:25 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/63edd55f971e2529552a65f1fba19135/departments.jar
16/09/09 02:46:25 WARN manager.MySQLManager: It looks like you are importing from mysql.
16/09/09 02:46:25 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
16/09/09 02:46:25 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
16/09/09 02:46:25 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
16/09/09 02:46:25 INFO mapreduce.ImportJobBase: Beginning import of departments
16/09/09 02:46:25 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/09 02:46:25 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/09/09 02:46:26 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/09/09 02:46:26 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/09 02:46:27 INFO db.DBInputFormat: Using read commited transaction isolation
16/09/09 02:46:27 INFO mapreduce.JobSubmitter: number of splits:1
16/09/09 02:46:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1473156829873_0018
16/09/09 02:46:28 INFO impl.YarnClientImpl: Submitted application application_1473156829873_0018
16/09/09 02:46:28 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1473156829873_0018/
16/09/09 02:46:28 INFO mapreduce.Job: Running job: job_1473156829873_0018
16/09/09 02:46:35 INFO mapreduce.Job: Job job_1473156829873_0018 running in uber mode : false
16/09/09 02:46:35 INFO mapreduce.Job:  map 0% reduce 0%
16/09/09 02:46:40 INFO mapreduce.Job:  map 100% reduce 0%
16/09/09 02:46:40 INFO mapreduce.Job: Job job_1473156829873_0018 completed successfully
16/09/09 02:46:40 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=138766
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=87
		HDFS: Number of bytes written=60
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Other local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3155
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=3155
		Total vcore-seconds taken by all map tasks=3155
		Total megabyte-seconds taken by all map tasks=3230720
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Input split bytes=87
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=46
		CPU time spent (ms)=870
		Physical memory (bytes) snapshot=205885440
		Virtual memory (bytes) snapshot=1575034880
		Total committed heap usage (bytes)=196608000
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=60
16/09/09 02:46:40 INFO mapreduce.ImportJobBase: Transferred 60 bytes in 14.5477 seconds (4.1244 bytes/sec)
16/09/09 02:46:40 INFO mapreduce.ImportJobBase: Retrieved 6 records.
[cloudera@quickstart Ejercicios Iniciales]$ hadoop fs -cat /user/cloudera/departments/part-m-00000 | more2,Fitness
3,Footwear
4,Apparel
5,Golf
6,Outdoors
7,Fan Shop
[cloudera@quickstart Ejercicios Iniciales]$ 


13. Trabajo con JOB. Esta mas pensado para guardar el ultimo last-value en un import incremental, nosotros lo haremos simple para probar:

[cloudera@quickstart Ejercicios Iniciales]$ sqoop job -help
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 02:49:38 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
usage: sqoop job [GENERIC-ARGS] [JOB-ARGS] [-- [<tool-name>] [TOOL-ARGS]]

Job management arguments:
   --create <job-id>            Create a new saved job
   --delete <job-id>            Delete a saved job
   --exec <job-id>              Run a saved job
   --help                       Print usage instructions
   --list                       List saved jobs
   --meta-connect <jdbc-uri>    Specify JDBC connect string for the
                                metastore
   --show <job-id>              Show the parameters for a saved job
   --verbose                    Print more information while working

Generic Hadoop command-line arguments:
(must preceed any tool-specific arguments)
Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|resourcemanager:port>    specify a ResourceManager
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]

[cloudera@quickstart Ejercicios Iniciales]$ sqoop job --create jobListRetailDB -- list-tables --connect jdbc:mysql://localhost/retail_db --username root --password cloudera
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 02:54:52 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/09 02:54:53 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.

[cloudera@quickstart Ejercicios Iniciales]$ sqoop job --list
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 02:55:13 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
Available jobs:
  jobListRetailDB

[cloudera@quickstart Ejercicios Iniciales]$ sqoop job --show jobListRetailDB
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 02:55:27 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
Enter password: 
Job: jobListRetailDB
Tool: list-tables
Options:
----------------------------
verbose = false
db.connect.string = jdbc:mysql://localhost/retail_db
codegen.output.delimiters.escape = 0
codegen.output.delimiters.enclose.required = false
codegen.input.delimiters.field = 0
split.limit = null
hbase.create.table = false
db.require.password = true
hdfs.append.dir = false
codegen.input.delimiters.escape = 0
import.fetch.size = null
accumulo.create.table = false
codegen.input.delimiters.enclose.required = false
db.username = root
reset.onemapper = false
codegen.output.delimiters.record = 10
import.max.inline.lob.size = 16777216
hbase.bulk.load.enabled = false
hcatalog.create.table = false
db.clear.staging.table = false
codegen.input.delimiters.record = 0
enable.compression = false
hive.overwrite.table = false
hive.import = false
codegen.input.delimiters.enclose = 0
accumulo.batch.size = 10240000
hive.drop.delims = false
customtool.options.jsonmap = {}
codegen.output.delimiters.enclose = 0
hdfs.delete-target.dir = false
codegen.output.dir = .
codegen.auto.compile.dir = true
relaxed.isolation = false
mapreduce.num.mappers = 4
accumulo.max.latency = 5000
import.direct.split.size = 0
codegen.output.delimiters.field = 44
export.new.update = UpdateOnly
incremental.mode = None
hdfs.file.format = TextFile
codegen.compile.dir = /tmp/sqoop-cloudera/compile/07f911254afbc878557419c038c42414
direct.import = false
hive.fail.table.exists = false
db.batch = false

[cloudera@quickstart Ejercicios Iniciales]$ sqoop job --exec jobListRetailDB
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 02:56:45 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
Enter password: 
16/09/09 02:56:50 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
categories
customers
departments
order_items
orders
products
[cloudera@quickstart Ejercicios Iniciales]$ 

OBS: Cuando intento hacer show o ejecutar me pide contraseña, le indico cloudera y ejecuta.


14. Exportar un directorio HDFS a una tabla en BBDD

La tool export no crea la tabla, solo la actualiza o inserta nuevos registros segun el update-mode y el update-key:

[cloudera@quickstart Ejercicios Iniciales]$ sqoop --options-file ./config/SqoopExportOptions.txt --export-dir /user/cloudera/departments/ --table nuevo_departments --update-mode allowinsert
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 03:15:03 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/09 03:15:03 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/09 03:15:03 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/09 03:15:03 INFO tool.CodeGenTool: Beginning code generation
16/09/09 03:15:03 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `nuevo_departments` AS t LIMIT 1
16/09/09 03:15:03 ERROR manager.SqlManager: Error executing statement: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'retail_db.nuevo_departments' doesn't exist
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'retail_db.nuevo_departments' doesn't exist
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.Util.getInstance(Util.java:360)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:978)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3887)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3823)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2435)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2582)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2530)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1907)
	at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:2030)
	at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:777)
	at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:786)
	at org.apache.sqoop.manager.SqlManager.getColumnInfoForRawQuery(SqlManager.java:289)
	at org.apache.sqoop.manager.SqlManager.getColumnTypesForRawQuery(SqlManager.java:260)
	at org.apache.sqoop.manager.SqlManager.getColumnTypes(SqlManager.java:246)
	at org.apache.sqoop.manager.ConnManager.getColumnTypes(ConnManager.java:327)
	at org.apache.sqoop.orm.ClassWriter.getColumnTypes(ClassWriter.java:1846)
	at org.apache.sqoop.orm.ClassWriter.generate(ClassWriter.java:1646)
	at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:107)
	at org.apache.sqoop.tool.ExportTool.exportTable(ExportTool.java:64)
	at org.apache.sqoop.tool.ExportTool.run(ExportTool.java:100)
	at org.apache.sqoop.Sqoop.run(Sqoop.java:143)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:179)
	at org.apache.sqoop.Sqoop.runTool(Sqoop.java:218)
	at org.apache.sqoop.Sqoop.runTool(Sqoop.java:227)
	at org.apache.sqoop.Sqoop.main(Sqoop.java:236)
16/09/09 03:15:03 ERROR tool.ExportTool: Encountered IOException running export job: java.io.IOException: No columns to generate for ClassWriter


Por lo tanto primero creamos una tabla en MySql:

mysql> CREATE TABLE new_departments(
    ->     id INT(11) NOT NULL PRIMARY KEY,
    ->     nombre VARCHAR(45));
Query OK, 0 rows affected (0.04 sec)

mysql> show tables;
+---------------------+
| Tables_in_retail_db |
+---------------------+
| categories          |
| customers           |
| departments         |
| new_departments     |
| order_items         |
| orders              |
| products            |
+---------------------+
7 rows in set (0.00 sec)

mysql> describe new_departments;
+--------+-------------+------+-----+---------+-------+
| Field  | Type        | Null | Key | Default | Extra |
+--------+-------------+------+-----+---------+-------+
| id     | int(11)     | NO   | PRI | NULL    |       |
| nombre | varchar(45) | YES  |     | NULL    |       |
+--------+-------------+------+-----+---------+-------+
2 rows in set (0.01 sec)


Ahora si podemos exportar:
Podemos importar sin indicar nada, pues simplemente insertara los registros:

[cloudera@quickstart Ejercicios Iniciales]$ sqoop --options-file ./config/SqoopExportOptions.txt --export-dir /user/cloudera/departments/ --table new_departments --update-mode allowinsert
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 03:31:21 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/09 03:31:21 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/09 03:31:21 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/09 03:31:21 INFO tool.CodeGenTool: Beginning code generation
16/09/09 03:31:21 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:31:21 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:31:21 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/64bd93a227503bc2e984196306ddb19f/new_departments.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/09/09 03:31:23 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/64bd93a227503bc2e984196306ddb19f/new_departments.jar
16/09/09 03:31:23 INFO mapreduce.ExportJobBase: Beginning export of new_departments
16/09/09 03:31:23 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/09 03:31:23 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/09/09 03:31:23 INFO Configuration.deprecation: mapred.map.max.attempts is deprecated. Instead, use mapreduce.map.maxattempts
16/09/09 03:31:24 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
16/09/09 03:31:24 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:31:24 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/09/09 03:31:24 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/09 03:31:25 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:31:25 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:31:25 INFO mapreduce.JobSubmitter: number of splits:4
16/09/09 03:31:25 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:31:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1473156829873_0020
16/09/09 03:31:26 INFO impl.YarnClientImpl: Submitted application application_1473156829873_0020
16/09/09 03:31:26 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1473156829873_0020/
16/09/09 03:31:26 INFO mapreduce.Job: Running job: job_1473156829873_0020
16/09/09 03:31:32 INFO mapreduce.Job: Job job_1473156829873_0020 running in uber mode : false
16/09/09 03:31:32 INFO mapreduce.Job:  map 0% reduce 0%
16/09/09 03:31:39 INFO mapreduce.Job:  map 25% reduce 0%
16/09/09 03:31:40 INFO mapreduce.Job:  map 50% reduce 0%
16/09/09 03:31:42 INFO mapreduce.Job:  map 100% reduce 0%
16/09/09 03:31:42 INFO mapreduce.Job: Job job_1473156829873_0020 completed successfully
16/09/09 03:31:42 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=553504
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=766
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Job Counters 
		Launched map tasks=4
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=20354
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=20354
		Total vcore-seconds taken by all map tasks=20354
		Total megabyte-seconds taken by all map tasks=20842496
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Input split bytes=604
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=260
		CPU time spent (ms)=3560
		Physical memory (bytes) snapshot=808517632
		Virtual memory (bytes) snapshot=6249050112
		Total committed heap usage (bytes)=786432000
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
16/09/09 03:31:42 INFO mapreduce.ExportJobBase: Transferred 766 bytes in 18.3341 seconds (41.7801 bytes/sec)
16/09/09 03:31:42 INFO mapreduce.ExportJobBase: Exported 6 records.
[cloudera@quickstart Ejercicios Iniciales]$ 


mysql> select * from new_departments;
+----+----------+
| id | nombre   |
+----+----------+
|  2 | Fitness  |
|  3 | Footwear |
|  4 | Apparel  |
|  5 | Golf     |
|  6 | Outdoors |
|  7 | Fan Shop |
+----+----------+
6 rows in set (0.00 sec)



Si ahora intentamos importar de nuevo, en principio nos deberia dar un error por clave duplicada:

[cloudera@quickstart Ejercicios Iniciales]$ sqoop --options-file ./config/SqoopExportOptions.txt --export-dir /user/cloudera/departments/ --table new_departments --update-mode allowinsert
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 03:33:25 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/09 03:33:25 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/09 03:33:25 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/09 03:33:25 INFO tool.CodeGenTool: Beginning code generation
16/09/09 03:33:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:33:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:33:25 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/55e5d7747eebb69da96b890ce14f7f27/new_departments.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/09/09 03:33:27 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/55e5d7747eebb69da96b890ce14f7f27/new_departments.jar
16/09/09 03:33:27 INFO mapreduce.ExportJobBase: Beginning export of new_departments
16/09/09 03:33:27 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/09 03:33:27 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/09/09 03:33:27 INFO Configuration.deprecation: mapred.map.max.attempts is deprecated. Instead, use mapreduce.map.maxattempts
16/09/09 03:33:28 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
16/09/09 03:33:28 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:33:28 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/09/09 03:33:28 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/09 03:33:30 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:33:30 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:33:30 INFO mapreduce.JobSubmitter: number of splits:4
16/09/09 03:33:30 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:33:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1473156829873_0021
16/09/09 03:33:31 INFO impl.YarnClientImpl: Submitted application application_1473156829873_0021
16/09/09 03:33:31 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1473156829873_0021/
16/09/09 03:33:31 INFO mapreduce.Job: Running job: job_1473156829873_0021
16/09/09 03:33:37 INFO mapreduce.Job: Job job_1473156829873_0021 running in uber mode : false
16/09/09 03:33:37 INFO mapreduce.Job:  map 0% reduce 0%
16/09/09 03:33:44 INFO mapreduce.Job:  map 100% reduce 0%
16/09/09 03:33:44 INFO mapreduce.Job: Job job_1473156829873_0021 failed with state FAILED due to: Task failed task_1473156829873_0021_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0

16/09/09 03:33:44 INFO mapreduce.Job: Counters: 12
	Job Counters 
		Failed map tasks=1
		Killed map tasks=3
		Launched map tasks=4
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=12268
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=12268
		Total vcore-seconds taken by all map tasks=12268
		Total megabyte-seconds taken by all map tasks=12562432
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
16/09/09 03:33:44 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
16/09/09 03:33:44 INFO mapreduce.ExportJobBase: Transferred 0 bytes in 15.955 seconds (0 bytes/sec)
16/09/09 03:33:44 INFO mapreduce.ExportJobBase: Exported 0 records.
16/09/09 03:33:44 ERROR tool.ExportTool: Error during export: Export job failed!
[cloudera@quickstart Ejercicios Iniciales]$ 



Tenemos que indicar --update-mode a updateonly e indicar --update-key id, y modificamos el fichero para que se vea el cambio:

[cloudera@quickstart Ejercicios Iniciales]$ hadoop fs -cat /user/cloudera/departments/part-m-00000 | more
2,Fitness
3,Footwear
4,Apparel
5,Golf Nuevo
6,Outdoors
7,Fan Shop
8,New Department

[cloudera@quickstart Ejercicios Iniciales]$ sqoop --options-file ./config/SqoopExportOptions.txt --export-dir /user/cloudera/departments/ --table new_departments --update-mode updateonly --update-key id
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 03:44:14 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/09 03:44:14 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/09 03:44:15 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/09 03:44:15 INFO tool.CodeGenTool: Beginning code generation
16/09/09 03:44:15 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:44:15 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:44:15 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/0d5d3b7514df4f8ef7078d20f4c99a98/new_departments.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/09/09 03:44:17 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/0d5d3b7514df4f8ef7078d20f4c99a98/new_departments.jar
16/09/09 03:44:17 INFO mapreduce.ExportJobBase: Beginning export of new_departments
16/09/09 03:44:17 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/09 03:44:17 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/09/09 03:44:17 INFO Configuration.deprecation: mapred.map.max.attempts is deprecated. Instead, use mapreduce.map.maxattempts
16/09/09 03:44:18 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
16/09/09 03:44:18 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:44:18 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/09/09 03:44:18 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/09 03:44:19 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:44:19 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:44:19 INFO mapreduce.JobSubmitter: number of splits:4
16/09/09 03:44:19 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:44:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1473156829873_0022
16/09/09 03:44:20 INFO impl.YarnClientImpl: Submitted application application_1473156829873_0022
16/09/09 03:44:20 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1473156829873_0022/
16/09/09 03:44:20 INFO mapreduce.Job: Running job: job_1473156829873_0022
16/09/09 03:44:27 INFO mapreduce.Job: Job job_1473156829873_0022 running in uber mode : false
16/09/09 03:44:27 INFO mapreduce.Job:  map 0% reduce 0%
16/09/09 03:44:35 INFO mapreduce.Job:  map 25% reduce 0%
16/09/09 03:44:37 INFO mapreduce.Job:  map 75% reduce 0%
16/09/09 03:44:38 INFO mapreduce.Job:  map 100% reduce 0%
16/09/09 03:44:39 INFO mapreduce.Job: Job job_1473156829873_0022 completed successfully
16/09/09 03:44:40 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=554600
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=930
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Job Counters 
		Launched map tasks=4
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=27041
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=27041
		Total vcore-seconds taken by all map tasks=27041
		Total megabyte-seconds taken by all map tasks=27689984
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Input split bytes=691
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=245
		CPU time spent (ms)=3560
		Physical memory (bytes) snapshot=766160896
		Virtual memory (bytes) snapshot=6247833600
		Total committed heap usage (bytes)=745013248
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
16/09/09 03:44:40 INFO mapreduce.ExportJobBase: Transferred 930 bytes in 21.6322 seconds (42.9914 bytes/sec)
16/09/09 03:44:40 INFO mapreduce.ExportJobBase: Exported 7 records.


mysql> select * from new_departments;
+----+------------+
| id | nombre     |
+----+------------+
|  2 | Fitness    |
|  3 | Footwear   |
|  4 | Apparel    |
|  5 | Golf Nuevo |
|  6 | Outdoors   |
|  7 | Fan Shop   |
+----+------------+
6 rows in set (0.00 sec)



IMP: Pero no inserta el nuevo registro, si actualiza el 5.

Si probamos a hacer update-mode allowinsert, da tambien error:
[cloudera@quickstart Ejercicios Iniciales]$ sqoop --options-file ./config/SqoopExportOptions.txt --export-dir /user/cloudera/departments/ --table new_departments --update-mode allowinsert
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 03:47:12 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/09 03:47:12 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/09 03:47:12 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/09 03:47:12 INFO tool.CodeGenTool: Beginning code generation
16/09/09 03:47:13 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:47:13 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:47:13 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/4fb8bad35278081eacf16130498bd33e/new_departments.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/09/09 03:47:15 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/4fb8bad35278081eacf16130498bd33e/new_departments.jar
16/09/09 03:47:15 INFO mapreduce.ExportJobBase: Beginning export of new_departments
16/09/09 03:47:15 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/09 03:47:15 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/09/09 03:47:15 INFO Configuration.deprecation: mapred.map.max.attempts is deprecated. Instead, use mapreduce.map.maxattempts
16/09/09 03:47:16 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
16/09/09 03:47:16 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:47:16 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/09/09 03:47:16 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/09 03:47:18 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:47:18 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:47:18 INFO mapreduce.JobSubmitter: number of splits:4
16/09/09 03:47:18 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:47:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1473156829873_0023
16/09/09 03:47:18 INFO impl.YarnClientImpl: Submitted application application_1473156829873_0023
16/09/09 03:47:18 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1473156829873_0023/
16/09/09 03:47:18 INFO mapreduce.Job: Running job: job_1473156829873_0023
16/09/09 03:47:27 INFO mapreduce.Job: Job job_1473156829873_0023 running in uber mode : false
16/09/09 03:47:27 INFO mapreduce.Job:  map 0% reduce 0%
16/09/09 03:47:37 INFO mapreduce.Job:  map 25% reduce 0%
16/09/09 03:47:38 INFO mapreduce.Job:  map 100% reduce 0%
16/09/09 03:47:38 INFO mapreduce.Job: Job job_1473156829873_0023 failed with state FAILED due to: Task failed task_1473156829873_0023_m_000001
Job failed as tasks failed. failedMaps:1 failedReduces:0

16/09/09 03:47:38 INFO mapreduce.Job: Counters: 32
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=138376
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=279
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Job Counters 
		Failed map tasks=1
		Killed map tasks=2
		Launched map tasks=4
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=31950
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=31950
		Total vcore-seconds taken by all map tasks=31950
		Total megabyte-seconds taken by all map tasks=32716800
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Input split bytes=238
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=113
		CPU time spent (ms)=1080
		Physical memory (bytes) snapshot=207925248
		Virtual memory (bytes) snapshot=1567371264
		Total committed heap usage (bytes)=196608000
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
16/09/09 03:47:38 INFO mapreduce.ExportJobBase: Transferred 279 bytes in 22.0136 seconds (12.674 bytes/sec)
16/09/09 03:47:38 INFO mapreduce.ExportJobBase: Exported 1 records.
16/09/09 03:47:38 ERROR tool.ExportTool: Error during export: Export job failed!

Y si incluimos update-key?? Modificamos de nuevo el fichero para asegurarnos del update tambien:
mysql> select * from new_departments;
+----+------------+
| id | nombre     |
+----+------------+
|  2 | Fitness    |
|  3 | Footwear   |
|  4 | Apparel    |
|  5 | Golf Nuevo |
|  6 | Outdoors   |
|  7 | Fan Shop   |
+----+------------+
6 rows in set (0.00 sec)

[cloudera@quickstart Ejercicios Iniciales]$ hadoop fs -cat /user/cloudera/departments/part-m-00000 | more
2,Fitness
3,Footwear
4,Apparel Nuevo
5,Golf Nuevo
6,Outdoors
7,Fan Shop
8,New Department


[cloudera@quickstart Ejercicios Iniciales]$ sqoop --options-file ./config/SqoopExportOptions.txt --export-dir /user/cloudera/departments/ --table new_departments --update-mode allowinsert --update-key id
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
16/09/09 03:54:43 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
16/09/09 03:54:43 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
16/09/09 03:54:43 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/09/09 03:54:43 INFO tool.CodeGenTool: Beginning code generation
16/09/09 03:54:44 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:54:44 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `new_departments` AS t LIMIT 1
16/09/09 03:54:44 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce
Note: /tmp/sqoop-cloudera/compile/918800da5409e5522679eeedc5448ab9/new_departments.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/09/09 03:54:45 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/918800da5409e5522679eeedc5448ab9/new_departments.jar
16/09/09 03:54:45 WARN manager.MySQLManager: MySQL Connector upsert functionality is using INSERT ON
16/09/09 03:54:45 WARN manager.MySQLManager: DUPLICATE KEY UPDATE clause that relies on table's unique key.
16/09/09 03:54:45 WARN manager.MySQLManager: Insert/update distinction is therefore independent on column
16/09/09 03:54:45 WARN manager.MySQLManager: names specified in --update-key parameter. Please see MySQL
16/09/09 03:54:45 WARN manager.MySQLManager: documentation for additional limitations.
16/09/09 03:54:45 INFO mapreduce.ExportJobBase: Beginning export of new_departments
16/09/09 03:54:45 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/09 03:54:46 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/09/09 03:54:46 INFO Configuration.deprecation: mapred.map.max.attempts is deprecated. Instead, use mapreduce.map.maxattempts
16/09/09 03:54:47 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
16/09/09 03:54:47 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:54:47 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/09/09 03:54:47 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/09 03:54:48 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:54:48 INFO input.FileInputFormat: Total input paths to process : 1
16/09/09 03:54:48 INFO mapreduce.JobSubmitter: number of splits:4
16/09/09 03:54:48 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
16/09/09 03:54:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1473156829873_0025
16/09/09 03:54:49 INFO impl.YarnClientImpl: Submitted application application_1473156829873_0025
16/09/09 03:54:49 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1473156829873_0025/
16/09/09 03:54:49 INFO mapreduce.Job: Running job: job_1473156829873_0025
16/09/09 03:54:56 INFO mapreduce.Job: Job job_1473156829873_0025 running in uber mode : false
16/09/09 03:54:56 INFO mapreduce.Job:  map 0% reduce 0%
16/09/09 03:55:05 INFO mapreduce.Job:  map 25% reduce 0%
16/09/09 03:55:06 INFO mapreduce.Job:  map 50% reduce 0%
16/09/09 03:55:07 INFO mapreduce.Job:  map 75% reduce 0%
16/09/09 03:55:08 INFO mapreduce.Job:  map 100% reduce 0%
16/09/09 03:55:08 INFO mapreduce.Job: Job job_1473156829873_0025 completed successfully
16/09/09 03:55:08 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=554660
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=942
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Job Counters 
		Launched map tasks=4
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=27360
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=27360
		Total vcore-seconds taken by all map tasks=27360
		Total megabyte-seconds taken by all map tasks=28016640
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Input split bytes=691
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=349
		CPU time spent (ms)=3820
		Physical memory (bytes) snapshot=717459456
		Virtual memory (bytes) snapshot=6274945024
		Total committed heap usage (bytes)=703594496
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
16/09/09 03:55:08 INFO mapreduce.ExportJobBase: Transferred 942 bytes in 21.555 seconds (43.7022 bytes/sec)
16/09/09 03:55:08 INFO mapreduce.ExportJobBase: Exported 7 records.



mysql> select * from new_departments;
+----+----------------+
| id | nombre         |
+----+----------------+
|  2 | Fitness        |
|  3 | Footwear       |
|  4 | Apparel Nuevo  |
|  5 | Golf Nuevo     |
|  6 | Outdoors       |
|  7 | Fan Shop       |
|  8 | New Department |
+----+----------------+
7 rows in set (0.00 sec)



AHORA SI ACTUALIZA E INSERTA. La solucion es la siguiente:
sqoop --options-file ./config/SqoopExportOptions.txt --export-dir /user/cloudera/departments/ --table new_departments --update-mode allowinsert --update-key id


















 


 

